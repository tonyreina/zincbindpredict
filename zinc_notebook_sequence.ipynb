{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b96e4d",
   "metadata": {},
   "source": [
    "https://github.com/samirelanduk/ZincBindPredict\n",
    "\n",
    "https://academic.oup.com/database/article/doi/10.1093/database/baz006/5304468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82540a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5601b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import utilities\n",
    "\n",
    "#utilities.get_all_pdb_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba1f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd0b35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending csv/sequence/H3.csv\n",
      "Appending csv/sequence/C2H2.csv\n",
      "Appending csv/sequence/C3H1.csv\n",
      "Appending csv/sequence/E1H1.csv\n",
      "Appending csv/sequence/C2H1.csv\n",
      "Appending csv/sequence/D1H1.csv\n",
      "Appending csv/sequence/E1H2.csv\n",
      "Appending csv/sequence/D1H2.csv\n",
      "Appending csv/sequence/C3.csv\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"csv/sequence/*.csv\")\n",
    "\n",
    "df = pd.read_csv(files[0])\n",
    "df[\"Type\"] = 0\n",
    "\n",
    "for idx, file in enumerate(files[1:]):\n",
    "\n",
    "    print(f\"Appending {file}\")\n",
    "    df_temp = pd.read_csv(file)\n",
    "    df_temp[\"Type\"] = idx+1\n",
    "    df = df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb0e1a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51042, 74)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ccc6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2b2c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"positive\"]\n",
    "zinc_type = df[\"Type\"]\n",
    "X = df.drop([\"positive\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70249c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, gap1 Score: 0.67502\n",
      "Feature: 1, hydrophobicity1 Score: 0.01901\n",
      "Feature: 2, gap2 Score: 0.05241\n",
      "Feature: 3, hydrophobicity2 Score: 0.00535\n",
      "Feature: 4, gap3 Score: 0.15102\n",
      "Feature: 5, hydrophobicity3 Score: 0.00599\n",
      "Feature: 6, hydrophobicity_window_1 Score: 0.00293\n",
      "Feature: 7, hydrophobicity_window_3 Score: 0.00255\n",
      "Feature: 8, hydrophobicity_window_5 Score: 0.00182\n",
      "Feature: 9, charged_window_1 Score: 0.00099\n",
      "Feature: 10, charged_window_3 Score: 0.00275\n",
      "Feature: 11, charged_window_5 Score: 0.00170\n",
      "Feature: 12, A_window_1 Score: 0.00082\n",
      "Feature: 13, A_window_3 Score: 0.00154\n",
      "Feature: 14, A_window_5 Score: 0.00114\n",
      "Feature: 15, R_window_1 Score: 0.00045\n",
      "Feature: 16, R_window_3 Score: 0.00094\n",
      "Feature: 17, R_window_5 Score: 0.00139\n",
      "Feature: 18, N_window_1 Score: 0.00048\n",
      "Feature: 19, N_window_3 Score: 0.00105\n",
      "Feature: 20, N_window_5 Score: 0.00076\n",
      "Feature: 21, D_window_1 Score: 0.00033\n",
      "Feature: 22, D_window_3 Score: 0.00206\n",
      "Feature: 23, D_window_5 Score: 0.00268\n",
      "Feature: 24, C_window_1 Score: 0.00442\n",
      "Feature: 25, C_window_3 Score: 0.00077\n",
      "Feature: 26, C_window_5 Score: 0.00588\n",
      "Feature: 27, E_window_1 Score: 0.00035\n",
      "Feature: 28, E_window_3 Score: 0.00099\n",
      "Feature: 29, E_window_5 Score: 0.00121\n",
      "Feature: 30, Q_window_1 Score: 0.00142\n",
      "Feature: 31, Q_window_3 Score: 0.00028\n",
      "Feature: 32, Q_window_5 Score: 0.00118\n",
      "Feature: 33, G_window_1 Score: 0.00050\n",
      "Feature: 34, G_window_3 Score: 0.00065\n",
      "Feature: 35, G_window_5 Score: 0.00260\n",
      "Feature: 36, H_window_1 Score: 0.00022\n",
      "Feature: 37, H_window_3 Score: 0.00162\n",
      "Feature: 38, H_window_5 Score: 0.00294\n",
      "Feature: 39, I_window_1 Score: 0.00042\n",
      "Feature: 40, I_window_3 Score: 0.00277\n",
      "Feature: 41, I_window_5 Score: 0.00247\n",
      "Feature: 42, L_window_1 Score: 0.00069\n",
      "Feature: 43, L_window_3 Score: 0.00088\n",
      "Feature: 44, L_window_5 Score: 0.00152\n",
      "Feature: 45, K_window_1 Score: 0.00014\n",
      "Feature: 46, K_window_3 Score: 0.00124\n",
      "Feature: 47, K_window_5 Score: 0.00184\n",
      "Feature: 48, M_window_1 Score: 0.00012\n",
      "Feature: 49, M_window_3 Score: 0.00082\n",
      "Feature: 50, M_window_5 Score: 0.00129\n",
      "Feature: 51, F_window_1 Score: 0.00158\n",
      "Feature: 52, F_window_3 Score: 0.00009\n",
      "Feature: 53, F_window_5 Score: 0.00101\n",
      "Feature: 54, P_window_1 Score: 0.00107\n",
      "Feature: 55, P_window_3 Score: 0.00151\n",
      "Feature: 56, P_window_5 Score: 0.00067\n",
      "Feature: 57, S_window_1 Score: 0.00077\n",
      "Feature: 58, S_window_3 Score: 0.00187\n",
      "Feature: 59, S_window_5 Score: 0.00349\n",
      "Feature: 60, T_window_1 Score: 0.00060\n",
      "Feature: 61, T_window_3 Score: 0.00210\n",
      "Feature: 62, T_window_5 Score: 0.00165\n",
      "Feature: 63, W_window_1 Score: 0.00036\n",
      "Feature: 64, W_window_3 Score: 0.00120\n",
      "Feature: 65, W_window_5 Score: 0.00152\n",
      "Feature: 66, Y_window_1 Score: 0.00023\n",
      "Feature: 67, Y_window_3 Score: 0.00071\n",
      "Feature: 68, Y_window_5 Score: 0.00186\n",
      "Feature: 69, V_window_1 Score: 0.00020\n",
      "Feature: 70, V_window_3 Score: 0.00084\n",
      "Feature: 71, V_window_5 Score: 0.00226\n",
      "Index(['gap1', 'gap3', 'gap2', 'hydrophobicity1', 'hydrophobicity3',\n",
      "       'C_window_5', 'hydrophobicity2', 'C_window_1', 'S_window_5',\n",
      "       'H_window_5', 'hydrophobicity_window_1', 'I_window_3',\n",
      "       'charged_window_3', 'D_window_5', 'G_window_5',\n",
      "       'hydrophobicity_window_3', 'I_window_5', 'V_window_5', 'T_window_3',\n",
      "       'D_window_3', 'S_window_3', 'Y_window_5', 'K_window_5',\n",
      "       'hydrophobicity_window_5', 'charged_window_5', 'T_window_5',\n",
      "       'H_window_3', 'F_window_1', 'A_window_3', 'W_window_5', 'L_window_5',\n",
      "       'P_window_3', 'Q_window_1', 'R_window_5', 'M_window_5', 'K_window_3',\n",
      "       'E_window_5', 'W_window_3', 'Q_window_5', 'A_window_5', 'P_window_1',\n",
      "       'N_window_3', 'F_window_5', 'charged_window_1', 'E_window_3',\n",
      "       'R_window_3', 'L_window_3', 'V_window_3', 'M_window_3', 'A_window_1',\n",
      "       'S_window_1', 'C_window_3', 'N_window_5', 'Y_window_3', 'L_window_1',\n",
      "       'P_window_5', 'G_window_3', 'T_window_1', 'G_window_1', 'N_window_1',\n",
      "       'R_window_1', 'I_window_1', 'W_window_1', 'E_window_1', 'D_window_1',\n",
      "       'Q_window_3', 'Y_window_1', 'H_window_1', 'V_window_1', 'K_window_1',\n",
      "       'M_window_1', 'F_window_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, %s Score: %.5f' % (i,df.columns[i], v))\n",
    "    \n",
    "print(df.columns[np.argsort(-importance)])\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38bd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap1</th>\n",
       "      <th>hydrophobicity1</th>\n",
       "      <th>gap2</th>\n",
       "      <th>hydrophobicity2</th>\n",
       "      <th>gap3</th>\n",
       "      <th>hydrophobicity3</th>\n",
       "      <th>hydrophobicity_window_1</th>\n",
       "      <th>hydrophobicity_window_3</th>\n",
       "      <th>hydrophobicity_window_5</th>\n",
       "      <th>charged_window_1</th>\n",
       "      <th>...</th>\n",
       "      <th>W_window_1</th>\n",
       "      <th>W_window_3</th>\n",
       "      <th>W_window_5</th>\n",
       "      <th>Y_window_1</th>\n",
       "      <th>Y_window_3</th>\n",
       "      <th>Y_window_5</th>\n",
       "      <th>V_window_1</th>\n",
       "      <th>V_window_3</th>\n",
       "      <th>V_window_5</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.658</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>30</td>\n",
       "      <td>0.151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.096</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.324</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>2</td>\n",
       "      <td>0.705</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>52</td>\n",
       "      <td>0.047</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.466</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>21</td>\n",
       "      <td>0.194</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.558</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33728 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gap1  hydrophobicity1   gap2  hydrophobicity2   gap3  hydrophobicity3  \\\n",
       "0         8            0.535    2.0            0.485    2.0            0.410   \n",
       "1         8            0.535    2.0            0.485    2.0            0.410   \n",
       "2         2            0.530   13.0            0.015    2.0            1.015   \n",
       "3         5            0.658    9.0            0.317    2.0            0.580   \n",
       "4         2            0.530   13.0            0.015    2.0            1.015   \n",
       "...     ...              ...    ...              ...    ...              ...   \n",
       "10995    30            0.151   40.0            0.096   86.0            0.362   \n",
       "10996     0            0.000  118.0            0.324   49.0            0.183   \n",
       "10997     2            0.705    6.0            0.150    6.0           -0.137   \n",
       "10998    52            0.047   33.0            0.466  223.0            0.204   \n",
       "10999    21            0.194    6.0            0.558  185.0            0.370   \n",
       "\n",
       "       hydrophobicity_window_1  hydrophobicity_window_3  \\\n",
       "0                        0.315                    0.168   \n",
       "1                        0.315                    0.168   \n",
       "2                        0.463                    0.210   \n",
       "3                        0.448                    0.375   \n",
       "4                        0.463                    0.210   \n",
       "...                        ...                      ...   \n",
       "10995                   -0.025                   -0.141   \n",
       "10996                    0.506                    0.350   \n",
       "10997                    0.357                    0.191   \n",
       "10998                    0.272                    0.265   \n",
       "10999                    0.280                    0.287   \n",
       "\n",
       "       hydrophobicity_window_5  charged_window_1  ...  W_window_1  W_window_3  \\\n",
       "0                        0.246             0.250  ...         0.0       0.000   \n",
       "1                        0.246             0.250  ...         0.0       0.000   \n",
       "2                        0.115             0.375  ...         0.0       0.000   \n",
       "3                        0.361             0.375  ...         0.0       0.000   \n",
       "4                        0.115             0.375  ...         0.0       0.000   \n",
       "...                        ...               ...  ...         ...         ...   \n",
       "10995                    0.013             0.000  ...         0.0       0.000   \n",
       "10996                    0.228             0.375  ...         0.0       0.000   \n",
       "10997                    0.169             0.250  ...         0.0       0.042   \n",
       "10998                    0.244             0.250  ...         0.0       0.000   \n",
       "10999                    0.500             0.250  ...         0.0       0.000   \n",
       "\n",
       "       W_window_5  Y_window_1  Y_window_3  Y_window_5  V_window_1  V_window_3  \\\n",
       "0           0.000         0.0       0.042       0.025       0.000       0.000   \n",
       "1           0.000         0.0       0.042       0.025       0.000       0.000   \n",
       "2           0.000         0.0       0.000       0.025       0.125       0.208   \n",
       "3           0.000         0.0       0.042       0.025       0.000       0.042   \n",
       "4           0.000         0.0       0.000       0.025       0.125       0.208   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "10995       0.000         0.0       0.042       0.050       0.000       0.000   \n",
       "10996       0.025         0.0       0.042       0.050       0.000       0.042   \n",
       "10997       0.050         0.0       0.000       0.000       0.250       0.083   \n",
       "10998       0.000         0.0       0.000       0.000       0.125       0.083   \n",
       "10999       0.000         0.0       0.042       0.025       0.000       0.042   \n",
       "\n",
       "       V_window_5  positive  \n",
       "0           0.000         1  \n",
       "1           0.000         1  \n",
       "2           0.125         1  \n",
       "3           0.025         1  \n",
       "4           0.125         1  \n",
       "...           ...       ...  \n",
       "10995       0.025         0  \n",
       "10996       0.075         0  \n",
       "10997       0.075         0  \n",
       "10998       0.100         0  \n",
       "10999       0.050         0  \n",
       "\n",
       "[33728 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be083be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"gap1\", \"gap2\", \"gap3\", \"positive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b274263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_model = tf.keras.layers.Input([df.shape[1]-1], name=\"myInput\")   \n",
    "\n",
    "layer1 = tf.keras.layers.Dense(units=256, activation=\"relu\", name=\"myLayer1\")(inputs_to_model)\n",
    "\n",
    "layer2 = tf.keras.layers.Dense(units=100, activation=\"relu\", name=\"yourLayer2\")(layer1)\n",
    "\n",
    "\n",
    "outputs_to_model = tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"myPrediction\")(layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c8d19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "myInput (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "myLayer1 (Dense)             (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "yourLayer2 (Dense)           (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "myPrediction (Dense)         (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 26,825\n",
      "Trainable params: 26,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(inputs=[inputs_to_model], outputs=[outputs_to_model])\n",
    "\n",
    "model.summary()  # Ask Keras to print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a357bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "#       tf.keras.metrics.TruePositives(name='tp'),\n",
    "#       tf.keras.metrics.FalsePositives(name='fp'),\n",
    "#       tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#       tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "#       tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5af4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f35367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8,random_state=816) #random state is a seed value\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4553e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"positive\"]\n",
    "x_train = train.iloc[:, :-1]\n",
    "\n",
    "y_test = test[\"positive\"]\n",
    "x_test = test.iloc[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0107b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae5412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15721), started 0:30:39 ago. (Use '!kill 15721' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-51e48b1243d38f50\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-51e48b1243d38f50\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e54f3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1687/1687 [==============================] - 18s 10ms/step - loss: 0.4012 - accuracy: 0.8647 - precision: 0.9040 - recall: 0.8091 - auc: 0.9413 - val_loss: 0.1713 - val_accuracy: 0.9434 - val_precision: 0.8127 - val_recall: 0.8453 - val_auc: 0.9704\n",
      "Epoch 2/30\n",
      "1687/1687 [==============================] - 20s 12ms/step - loss: 0.2006 - accuracy: 0.9396 - precision: 0.9237 - recall: 0.9568 - auc: 0.9744 - val_loss: 0.1551 - val_accuracy: 0.9401 - val_precision: 0.7391 - val_recall: 0.9742 - val_auc: 0.9820\n",
      "Epoch 3/30\n",
      "1687/1687 [==============================] - 15s 9ms/step - loss: 0.1629 - accuracy: 0.9450 - precision: 0.9302 - recall: 0.9625 - auc: 0.9790 - val_loss: 0.1829 - val_accuracy: 0.9234 - val_precision: 0.6818 - val_recall: 0.9885 - val_auc: 0.9827\n",
      "Epoch 4/30\n",
      "1687/1687 [==============================] - 25s 15ms/step - loss: 0.1468 - accuracy: 0.9506 - precision: 0.9350 - recall: 0.9689 - auc: 0.9824 - val_loss: 0.1588 - val_accuracy: 0.9359 - val_precision: 0.7298 - val_recall: 0.9599 - val_auc: 0.9817\n",
      "Epoch 5/30\n",
      "1687/1687 [==============================] - 25s 15ms/step - loss: 0.1370 - accuracy: 0.9520 - precision: 0.9389 - recall: 0.9676 - auc: 0.9847 - val_loss: 0.1283 - val_accuracy: 0.9517 - val_precision: 0.7882 - val_recall: 0.9599 - val_auc: 0.9851\n",
      "Epoch 6/30\n",
      "1687/1687 [==============================] - 10s 6ms/step - loss: 0.1372 - accuracy: 0.9529 - precision: 0.9404 - recall: 0.9674 - auc: 0.9838 - val_loss: 0.1373 - val_accuracy: 0.9480 - val_precision: 0.7749 - val_recall: 0.9570 - val_auc: 0.9847\n",
      "Epoch 7/30\n",
      "1687/1687 [==============================] - 8s 5ms/step - loss: 0.1296 - accuracy: 0.9550 - precision: 0.9445 - recall: 0.9668 - auc: 0.9858 - val_loss: 0.1710 - val_accuracy: 0.9345 - val_precision: 0.7167 - val_recall: 0.9857 - val_auc: 0.9853\n",
      "Epoch 8/30\n",
      "1687/1687 [==============================] - 10s 6ms/step - loss: 0.1295 - accuracy: 0.9540 - precision: 0.9418 - recall: 0.9680 - auc: 0.9860 - val_loss: 0.1471 - val_accuracy: 0.9438 - val_precision: 0.7511 - val_recall: 0.9771 - val_auc: 0.9862\n",
      "Epoch 9/30\n",
      "1687/1687 [==============================] - 25s 15ms/step - loss: 0.1285 - accuracy: 0.9542 - precision: 0.9412 - recall: 0.9694 - auc: 0.9847 - val_loss: 0.1193 - val_accuracy: 0.9531 - val_precision: 0.8010 - val_recall: 0.9456 - val_auc: 0.9853\n",
      "Epoch 10/30\n",
      "1687/1687 [==============================] - 13s 8ms/step - loss: 0.1247 - accuracy: 0.9564 - precision: 0.9455 - recall: 0.9699 - auc: 0.9862 - val_loss: 0.1454 - val_accuracy: 0.9452 - val_precision: 0.7561 - val_recall: 0.9771 - val_auc: 0.9854\n",
      "Epoch 11/30\n",
      "1687/1687 [==============================] - 47s 28ms/step - loss: 0.1206 - accuracy: 0.9581 - precision: 0.9445 - recall: 0.9728 - auc: 0.9861 - val_loss: 0.1550 - val_accuracy: 0.9401 - val_precision: 0.7381 - val_recall: 0.9771 - val_auc: 0.9849\n",
      "Epoch 12/30\n",
      "1687/1687 [==============================] - 70s 42ms/step - loss: 0.1269 - accuracy: 0.9565 - precision: 0.9440 - recall: 0.9702 - auc: 0.9856 - val_loss: 0.1405 - val_accuracy: 0.9508 - val_precision: 0.7743 - val_recall: 0.9828 - val_auc: 0.9853\n",
      "Epoch 13/30\n",
      "1687/1687 [==============================] - 28s 17ms/step - loss: 0.1261 - accuracy: 0.9558 - precision: 0.9440 - recall: 0.9692 - auc: 0.9860 - val_loss: 0.1352 - val_accuracy: 0.9517 - val_precision: 0.7803 - val_recall: 0.9771 - val_auc: 0.9865\n",
      "Epoch 14/30\n",
      "1687/1687 [==============================] - 28s 17ms/step - loss: 0.1201 - accuracy: 0.9568 - precision: 0.9420 - recall: 0.9728 - auc: 0.9867 - val_loss: 0.1384 - val_accuracy: 0.9508 - val_precision: 0.7819 - val_recall: 0.9656 - val_auc: 0.9868\n",
      "Epoch 15/30\n",
      "1687/1687 [==============================] - 24s 14ms/step - loss: 0.1176 - accuracy: 0.9589 - precision: 0.9482 - recall: 0.9708 - auc: 0.9877 - val_loss: 0.1249 - val_accuracy: 0.9573 - val_precision: 0.8052 - val_recall: 0.9713 - val_auc: 0.9860\n",
      "Epoch 16/30\n",
      "1687/1687 [==============================] - 22s 13ms/step - loss: 0.1183 - accuracy: 0.9591 - precision: 0.9472 - recall: 0.9717 - auc: 0.9870 - val_loss: 0.1209 - val_accuracy: 0.9554 - val_precision: 0.8093 - val_recall: 0.9484 - val_auc: 0.9861\n",
      "Epoch 17/30\n",
      "1687/1687 [==============================] - 22s 13ms/step - loss: 0.1131 - accuracy: 0.9606 - precision: 0.9513 - recall: 0.9715 - auc: 0.9882 - val_loss: 0.1360 - val_accuracy: 0.9503 - val_precision: 0.7763 - val_recall: 0.9742 - val_auc: 0.9858\n",
      "Epoch 18/30\n",
      "1687/1687 [==============================] - 18s 11ms/step - loss: 0.1117 - accuracy: 0.9598 - precision: 0.9466 - recall: 0.9740 - auc: 0.9882 - val_loss: 0.1281 - val_accuracy: 0.9531 - val_precision: 0.7952 - val_recall: 0.9570 - val_auc: 0.9846\n",
      "Epoch 19/30\n",
      "1687/1687 [==============================] - 19s 11ms/step - loss: 0.1138 - accuracy: 0.9605 - precision: 0.9479 - recall: 0.9745 - auc: 0.9872 - val_loss: 0.1405 - val_accuracy: 0.9415 - val_precision: 0.7483 - val_recall: 0.9628 - val_auc: 0.9859\n",
      "Epoch 20/30\n",
      "1687/1687 [==============================] - 20s 12ms/step - loss: 0.1095 - accuracy: 0.9630 - precision: 0.9529 - recall: 0.9741 - auc: 0.9886 - val_loss: 0.1269 - val_accuracy: 0.9540 - val_precision: 0.7976 - val_recall: 0.9599 - val_auc: 0.9867\n",
      "Epoch 21/30\n",
      "1687/1687 [==============================] - 18s 11ms/step - loss: 0.1151 - accuracy: 0.9588 - precision: 0.9474 - recall: 0.9720 - auc: 0.9871 - val_loss: 0.1231 - val_accuracy: 0.9601 - val_precision: 0.8215 - val_recall: 0.9628 - val_auc: 0.9876\n",
      "Epoch 22/30\n",
      "1687/1687 [==============================] - 39s 23ms/step - loss: 0.1113 - accuracy: 0.9608 - precision: 0.9503 - recall: 0.9732 - auc: 0.9881 - val_loss: 0.1251 - val_accuracy: 0.9564 - val_precision: 0.8087 - val_recall: 0.9570 - val_auc: 0.9858\n",
      "Epoch 23/30\n",
      "1687/1687 [==============================] - 34s 20ms/step - loss: 0.1092 - accuracy: 0.9608 - precision: 0.9496 - recall: 0.9736 - auc: 0.9887 - val_loss: 0.1333 - val_accuracy: 0.9489 - val_precision: 0.7710 - val_recall: 0.9742 - val_auc: 0.9865\n",
      "Epoch 24/30\n",
      "1687/1687 [==============================] - 33s 19ms/step - loss: 0.1091 - accuracy: 0.9620 - precision: 0.9520 - recall: 0.9734 - auc: 0.9886 - val_loss: 0.1288 - val_accuracy: 0.9536 - val_precision: 0.7889 - val_recall: 0.9742 - val_auc: 0.9867\n",
      "Epoch 25/30\n",
      "1687/1687 [==============================] - 29s 17ms/step - loss: 0.1116 - accuracy: 0.9596 - precision: 0.9496 - recall: 0.9697 - auc: 0.9884 - val_loss: 0.1211 - val_accuracy: 0.9554 - val_precision: 0.8019 - val_recall: 0.9628 - val_auc: 0.9873\n",
      "Epoch 26/30\n",
      "1687/1687 [==============================] - 32s 19ms/step - loss: 0.1076 - accuracy: 0.9636 - precision: 0.9544 - recall: 0.9739 - auc: 0.9890 - val_loss: 0.2231 - val_accuracy: 0.9420 - val_precision: 0.7424 - val_recall: 0.9828 - val_auc: 0.9749\n",
      "Epoch 27/30\n",
      "1687/1687 [==============================] - 32s 19ms/step - loss: 0.1064 - accuracy: 0.9630 - precision: 0.9553 - recall: 0.9723 - auc: 0.9896 - val_loss: 0.1237 - val_accuracy: 0.9554 - val_precision: 0.7963 - val_recall: 0.9742 - val_auc: 0.9881\n",
      "Epoch 28/30\n",
      "1687/1687 [==============================] - 28s 17ms/step - loss: 0.1047 - accuracy: 0.9634 - precision: 0.9546 - recall: 0.9730 - auc: 0.9892 - val_loss: 0.1189 - val_accuracy: 0.9564 - val_precision: 0.7986 - val_recall: 0.9771 - val_auc: 0.9874\n",
      "Epoch 29/30\n",
      "1687/1687 [==============================] - 31s 18ms/step - loss: 0.1020 - accuracy: 0.9655 - precision: 0.9549 - recall: 0.9769 - auc: 0.9896 - val_loss: 0.1210 - val_accuracy: 0.9526 - val_precision: 0.7865 - val_recall: 0.9713 - val_auc: 0.9869\n",
      "Epoch 30/30\n",
      "1687/1687 [==============================] - 36s 21ms/step - loss: 0.1064 - accuracy: 0.9632 - precision: 0.9533 - recall: 0.9738 - auc: 0.9892 - val_loss: 0.1412 - val_accuracy: 0.9508 - val_precision: 0.7780 - val_recall: 0.9742 - val_auc: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5649d0fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_epochs = 30\n",
    "model.fit(x_train, y_train, epochs=number_of_epochs, batch_size=16, \n",
    "          verbose=1, validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a588b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zinc_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b835e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
